{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "style.use(\"ggplot\")\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold,cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Ridge, Lasso\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crime = pd.read_csv('crimedata2.csv', encoding = \"ISO-8859-1\")\n",
    "crime = pd.read_csv('/content/sample_data/crimedata2.csv', encoding = \"ISO-8859-1\")\n",
    "crime.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_pb = crime[['autoTheft','numbUrban', 'pctUrban', 'medIncome', 'pctWWage','pctWFarmSelf', 'pctWInvInc', 'pctWSocSec', 'pctWPubAsst', 'pctWRetire',\n",
    "                  'medFamInc','perCapInc','NumUnderPov', 'PctPopUnderPov','PctNotHSGrad', 'PctBSorMore', 'PctUnemployed', 'PctEmploy', 'PctEmplManu',\n",
    "                  'PctEmplProfServ', 'PctOccupManu', 'PctOccupMgmtProf','PctLargHouseOccup', 'PersPerOccupHous', 'PersPerOwnOccHous', 'PersPerRentOccHous',\n",
    "                 'PctPersOwnOccup', 'PctPersDenseHous', 'MedNumBR', 'HousVacant', 'PctHousOccup', 'PctHousOwnOcc', 'PctVacantBoarded','PctVacMore6Mos',\n",
    "                 'MedRent', 'MedOwnCostPctInc', 'MedOwnCostPctIncNoMtg' ,'PctBornSameState', 'PctSameHouse85', 'PctSameCity85', 'PctSameState85']]\n",
    "#Convert '?' to NaN\n",
    "crime_pb = crime_pb.replace('?', float('nan'))\n",
    "\n",
    "#Get the correlations\n",
    "crime_pb = crime_pb.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "#Drop rows with NaN values\n",
    "crime_pb = crime_pb.dropna()\n",
    "corr = crime_pb.corr()\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.heatmap(corr,annot=True, fmt=\".2f\", cmap='viridis')\n",
    "plt.title('Correlation Heatmap', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoCrime_pb= crime[['pctUrban', 'medIncome', 'PctPopUnderPov', 'PctLess9thGrade', 'PctNotHSGrad',\n",
    "                     'PctBSorMore','PctEmploy', 'PctUnemployed',  'PctVacMore6Mos','numbUrban',\n",
    "                     'PctVacantBoarded','agePct12t29','agePct16t24','agePct65up','RentMedian',\n",
    "                     'racepctblack', 'racePctWhite', 'racePctAsian', 'racePctHisp', 'PctUsePubTrans','autoTheft','HousVacant']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoCrime_pb =  autoCrime_pb.apply(pd.to_numeric, errors='coerce')\n",
    "# Convert '?' to NaN\n",
    "autoCrime_pb = autoCrime_pb.replace('?', float('nan'))\n",
    "# Drop rows with NaN values\n",
    "autoCrime_pb = autoCrime_pb.dropna()\n",
    "autoCrime_pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the correlations\n",
    "autoCrime_pb =  autoCrime_pb.apply(pd.to_numeric, errors='coerce')\n",
    "# Convert '?' to NaN\n",
    "autoCrime_pB = autoCrime_pb.replace('?', float('nan'))\n",
    "# Drop rows with NaN values\n",
    "autoCrime_pb = autoCrime_pb.dropna()\n",
    "corr = autoCrime_pb.corr()\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.heatmap(corr,annot=True, fmt=\".2f\", cmap='viridis')\n",
    "plt.title('Correlation Heatmap', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoCrime_pb1= crime[['pctUrban', 'medIncome', 'PctPopUnderPov', 'PctLess9thGrade', 'PctNotHSGrad', 'PctBSorMore','PctEmploy', 'PctUnemployed', 'HousVacant','PctVacantBoarded', 'PctVacMore6Mos',\n",
    "                     'RentMedian', 'PctUsePubTrans','autoTheft']]\n",
    "autoCrime_pb1 =  autoCrime_pb1.apply(pd.to_numeric, errors='coerce')\n",
    "# Convert '?' to NaN\n",
    "autoCrime_p1b = autoCrime_pb1.replace('?', float('nan'))\n",
    "# Drop rows with NaN values\n",
    "autoCrime_pb1 = autoCrime_pb1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the correlations\n",
    "corr = autoCrime_pb1.corr()\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.heatmap(corr,annot=True, fmt=\".2f\", cmap='viridis')\n",
    "plt.title('Correlation Heatmap', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoCrime_pb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoCrime_pb1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = autoCrime_pb1[[\"medIncome\", \"HousVacant\",\"autoTheft\"]]\n",
    "B1.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B2 = autoCrime_pb1[['pctUrban', 'PctPopUnderPov', 'PctNotHSGrad', 'PctBSorMore','PctEmploy', 'PctUnemployed', 'PctVacMore6Mos',\n",
    "                    'PctUsePubTrans']]\n",
    "B2.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B3 = autoCrime_pb1[[ 'RentMedian']]\n",
    "B3.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "autoCrime_pb1_standard = pd.DataFrame(StandardScaler().fit_transform(autoCrime_pb1),columns = autoCrime_pb1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoCrime_pb1_standard.boxplot()\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = autoCrime_pb[['pctUrban', 'medIncome', 'PctPopUnderPov','PctVacantBoarded','numbUrban',\n",
    "       'PctNotHSGrad', 'PctBSorMore', 'PctEmploy', 'PctUnemployed', 'HousVacant',\n",
    "        'PctVacMore6Mos', 'agePct12t29','agePct16t24', 'agePct65up', 'RentMedian',\n",
    "        'racepctblack','racePctWhite', 'racePctAsian', 'racePctHisp', 'PctUsePubTrans']]\n",
    "Y= autoCrime_pb['autoTheft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data partition. Random state can be any number, just has to be consistent throughout the code\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state =21) # Random state can be any number, just has to be consistent throughout the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=21),\n",
    "    'Random Forest': RandomForestRegressor(random_state=21),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=21)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 5\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=21)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    mse_scores = -cross_val_score(model, X, Y, cv=kf, scoring = 'neg_mean_squared_error')\n",
    "    rmse_scores = -cross_val_score(model, X, Y, cv=kf, scoring = 'neg_root_mean_squared_error')\n",
    "    r2_scores = cross_val_score(model, X, Y, cv=kf, scoring='r2')\n",
    "\n",
    "    results[name] = {\n",
    "        'MSE': mse_scores,\n",
    "        'MSE Mean': np.mean(mse_scores),\n",
    "        'MSE Std': np.std(mse_scores),\n",
    "        'RMSE': rmse_scores,\n",
    "        'RMSE Mean': np.mean(rmse_scores),\n",
    "        'RMSE Std': np.std(rmse_scores),\n",
    "        'R2': r2_scores,\n",
    "        'R2 Mean': np.mean(r2_scores),\n",
    "        'R2 Std': np.std(r2_scores)\n",
    "    }\n",
    "\n",
    "# Print Results\n",
    "for name, metrics in results.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"Mean MSE: {metrics['MSE Mean']:.2f}, Std MSE: {metrics['MSE Std']:.2f}\")\n",
    "    print(f\"Mean RMSE: {metrics['RMSE Mean']:.2f}, Std RMSE: {metrics['RMSE Std']:.2f}\")\n",
    "    print(f\"Mean R2: {metrics['R2 Mean']:.2f}, Std R2: {metrics['R2 Std']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k = 10\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=21)    # 10 folds\n",
    "results1 = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    mse_scores = -cross_val_score(model, X, Y, cv=kf, scoring = 'neg_mean_squared_error')\n",
    "    rmse_scores = -cross_val_score(model, X, Y, cv=kf, scoring = 'neg_root_mean_squared_error')\n",
    "    r2_scores = cross_val_score(model, X, Y, cv=kf, scoring='r2')\n",
    "\n",
    "    results1[name] = {\n",
    "        'MSE': mse_scores,\n",
    "        'MSE Mean': np.mean(mse_scores),\n",
    "        'MSE Std': np.std(mse_scores),\n",
    "        'RMSE': rmse_scores,\n",
    "        'RMSE Mean': np.mean(rmse_scores),\n",
    "        'RMSE Std': np.std(rmse_scores),\n",
    "        'R2': r2_scores,\n",
    "        'R2 Mean': np.mean(r2_scores),\n",
    "        'R2 Std': np.std(r2_scores)\n",
    "    }\n",
    "\n",
    "# Print Results\n",
    "for name, metrics in results1.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"Mean MSE: {metrics['MSE Mean']:.2f}, Std MSE: {metrics['MSE Std']:.2f}\")\n",
    "    print(f\"Mean RMSE: {metrics['RMSE Mean']:.2f}, Std RMSE: {metrics['RMSE Std']:.2f}\")\n",
    "    print(f\"Mean R2: {metrics['R2 Mean']:.2f}, Std R2: {metrics['R2 Std']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR REGRESSION\n",
    "\n",
    "k = 5\n",
    "crossvalidation = KFold(n_splits=k, shuffle=True, random_state=21)\n",
    "\n",
    "# Fit regression model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "r2_scores = []\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "\n",
    "\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in crossvalidation.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    reg.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"Fold results: R-squared = {r2:.4f}, MSE = {mse:.4f}, RMSE = {rmse:.4f}\")\n",
    "\n",
    "# Print average metrics across all folds\n",
    "print(f\"\\nAverage results: R-squared = {np.mean(r2_scores):.4f}, MSE = {np.mean(mse_scores):.4f}, RMSE = {np.mean(rmse_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISON TREE\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the model\n",
    "dt = DecisionTreeRegressor(random_state=21)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "r2_scores = []\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "crossvalidation = KFold(n_splits=k, shuffle=True, random_state=21)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in crossvalidation.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    dt.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = dt.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"Fold results: R-squared = {r2:.4f}, MSE = {mse:.4f}, RMSE = {rmse:.4f}\")\n",
    "\n",
    "# Print average metrics across all folds\n",
    "print(f\"\\nAverage results: R-squared = {np.mean(r2_scores):.4f}, MSE = {np.mean(mse_scores):.4f}, RMSE = {np.mean(rmse_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(random_state=21)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "r2_scores = []\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "crossvalidation = KFold(n_splits=k, shuffle=True, random_state=21)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in crossvalidation.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    rf.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"Fold results: R-squared = {r2:.4f}, MSE = {mse:.4f}, RMSE = {rmse:.4f}\")\n",
    "\n",
    "# Print average metrics across all folds\n",
    "print(f\"\\nAverage results: R-squared = {np.mean(r2_scores):.4f}, MSE = {np.mean(mse_scores):.4f}, RMSE = {np.mean(rmse_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRADIENT BOOSTING\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingRegressor(random_state=21)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "r2_scores = []\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "#crossvalidation = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in crossvalidation.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    gbc.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = gbc.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"Fold results: R-squared = {r2:.4f}, MSE = {mse:.4f}, RMSE = {rmse:.4f}\")\n",
    "\n",
    "# Print average metrics across all folds\n",
    "print(f\"\\nAverage results: R-squared = {np.mean(r2_scores):.4f}, MSE = {np.mean(mse_scores):.4f}, RMSE = {np.mean(rmse_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAIVE BAYES\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "r2_scores = []\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "crossvalidation = KFold(n_splits=k, shuffle=True, random_state=21)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in crossvalidation.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    nb.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = nb.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"Fold results: R-squared = {r2:.4f}, MSE = {mse:.4f}, RMSE = {rmse:.4f}\")\n",
    "\n",
    "# Print average metrics across all folds\n",
    "print(f\"\\nAverage results: R-squared = {np.mean(r2_scores):.4f}, MSE = {np.mean(mse_scores):.4f}, RMSE = {np.mean(rmse_scores):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model for k =10\n",
    "\n",
    "k = 10\n",
    "crossvalidation = KFold(n_splits=k, random_state=21, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR REGRESSION\n",
    "\n",
    "# Fit regression model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "r2_scores = []\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "\n",
    "\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in crossvalidation.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    reg.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"Fold results: R-squared = {r2:.4f}, MSE = {mse:.4f}, RMSE = {rmse:.4f}\")\n",
    "\n",
    "# Print average metrics across all folds\n",
    "print(f\"\\nAverage results: R-squared = {np.mean(r2_scores):.4f}, MSE = {np.mean(mse_scores):.4f}, RMSE = {np.mean(rmse_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Assume y_test and y_pred are your observed and predicted values\n",
    "residuals = Y_test - y_pred\n",
    "\n",
    "'''\n",
    "In the Residuals vs. Fitted Values Plot, residuals should be randomly scattered around zero without any apparent pattern.\n",
    "A clear pattern indicates that the model may not be appropriate.\n",
    "'''\n",
    "\n",
    "# Residuals vs Fitted Values Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs Fitted Values')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "resemble a normal distribution.\n",
    "'''\n",
    "\n",
    "# Histogram of Residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "Q-Q Plot should show points lying close to the line, indicating normality.\n",
    "'''\n",
    "\n",
    "# Q-Q Plot\n",
    "sm.qqplot(residuals, line='45')\n",
    "plt.title('Q-Q Plot')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "Shapiro-Wilk Test: Tests the normality of the residuals.\n",
    "A p-value greater than the significance level (commonly 0.05) indicates that the residuals are normally distributed.\n",
    "'''\n",
    "\n",
    "# Shapiro-Wilk Test for Normality\n",
    "shapiro_test = shapiro(residuals)\n",
    "print('Shapiro-Wilk Test p-value:', shapiro_test.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISION TREE\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the model\n",
    "dt = DecisionTreeRegressor(random_state=21)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "r2_scores = []\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "crossvalidation = KFold(n_splits=k, shuffle=True, random_state=21)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in crossvalidation.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    dt.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = dt.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"Fold results: R-squared = {r2:.4f}, MSE = {mse:.4f}, RMSE = {rmse:.4f}\")\n",
    "\n",
    "# Print average metrics across all folds\n",
    "print(f\"\\nAverage results: R-squared = {np.mean(r2_scores):.4f}, MSE = {np.mean(mse_scores):.4f}, RMSE = {np.mean(rmse_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(random_state=21)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "r2_scores = []\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "crossvalidation = KFold(n_splits=k, shuffle=True, random_state=21)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in crossvalidation.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    rf.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"Fold results: R-squared = {r2:.4f}, MSE = {mse:.4f}, RMSE = {rmse:.4f}\")\n",
    "\n",
    "# Print average metrics across all folds\n",
    "print(f\"\\nAverage results: R-squared = {np.mean(r2_scores):.4f}, MSE = {np.mean(mse_scores):.4f}, RMSE = {np.mean(rmse_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRADIENT BOOSTING\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingRegressor(random_state=21)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "r2_scores = []\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "#crossvalidation = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in crossvalidation.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    gbc.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = gbc.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"Fold results: R-squared = {r2:.4f}, MSE = {mse:.4f}, RMSE = {rmse:.4f}\")\n",
    "\n",
    "# Print average metrics across all folds\n",
    "print(f\"\\nAverage results: R-squared = {np.mean(r2_scores):.4f}, MSE = {np.mean(mse_scores):.4f}, RMSE = {np.mean(rmse_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAIVE BOOSTING\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "r2_scores = []\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "#crossvalidation = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in crossvalidation.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    nb.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = nb.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"Fold results: R-squared = {r2:.4f}, MSE = {mse:.4f}, RMSE = {rmse:.4f}\")\n",
    "\n",
    "# Print average metrics across all folds\n",
    "print(f\"\\nAverage results: R-squared = {np.mean(r2_scores):.4f}, MSE = {np.mean(mse_scores):.4f}, RMSE = {np.mean(rmse_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRID SEARCH\n",
    "#RIDGE REGRESSION\n",
    "\n",
    "# Define parameter grid for Ridge\n",
    "grid1 = {'alpha': [0.1, 0.5, 1,10,25,75, 85,100]}\n",
    "\n",
    "# Ridge Regression with GridSearchCV\n",
    "ridge = Ridge(random_state=21)\n",
    "ridge_cv = GridSearchCV(ridge, grid1, cv=5)\n",
    "ridge_cv.fit(X_train, Y_train)\n",
    "ridge_best = ridge_cv.best_estimator_\n",
    "print(f'Best Parameters: {ridge_best}')\n",
    "\n",
    "# Make predictions and evaluate performance\n",
    "y_pred = ridge_best.predict(X_test)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for Ridge\n",
    "grid1 = {'alpha': [0.1, 0.5, 1,10,25,75, 85,100]}\n",
    "\n",
    "# Ridge Regression with GridSearchCV\n",
    "ridge = Ridge(random_state=21)\n",
    "ridge_cv = GridSearchCV(ridge, grid1, cv=10)\n",
    "ridge_cv.fit(X_train, Y_train)\n",
    "ridge_best = ridge_cv.best_estimator_\n",
    "print(f'Best Parameters: {ridge_best}')\n",
    "\n",
    "# Make predictions and evaluate performance\n",
    "y_pred = ridge_best.predict(X_test)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO REGRESSION\n",
    "\n",
    "# Lasso Regression with GridSearchCV\n",
    "grid2 = {'alpha': [0.1, 0.5, 1,10,25,75, 85,100]}\n",
    "\n",
    "lasso = Lasso(random_state=21)\n",
    "lasso_cv = GridSearchCV(lasso, grid2, cv=5)\n",
    "lasso_cv.fit(X_train, Y_train)\n",
    "lasso_best = lasso_cv.best_estimator_\n",
    "print(f'Best Parameters: {lasso_best}')\n",
    "\n",
    "# Make predictions and evaluate performance\n",
    "y_pred = lasso_best.predict(X_test)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression with GridSearchCV\n",
    "grid2 = {'alpha': [0.1, 0.5, 1,10,25,75, 85,100]}\n",
    "\n",
    "lasso = Lasso(random_state=21)\n",
    "lasso_cv = GridSearchCV(lasso, grid2, cv=10)\n",
    "lasso_cv.fit(X_train, Y_train)\n",
    "lasso_best = lasso_cv.best_estimator_\n",
    "print(f'Best Parameters: {lasso_best}')\n",
    "\n",
    "# Make predictions and evaluate performance\n",
    "y_pred = lasso_best.predict(X_test)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE\n",
    "\n",
    "# Define parameter grid\n",
    "grid3 = {\n",
    "    'max_depth': [2, 4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "decision_tree = DecisionTreeRegressor(random_state=21)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(decision_tree, grid3, cv=5, scoring= 'neg_mean_squared_error')\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Best model and its parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Parameters: {best_params}')\n",
    "\n",
    "# Make predictions and evaluate performance\n",
    "y_pred = best_model.predict(X_test)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "grid3 = {\n",
    "    'max_depth': [2, 4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "decision_tree = DecisionTreeRegressor(random_state=21)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(decision_tree, grid3, cv=10, scoring= 'neg_mean_squared_error')\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Best model and its parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Parameters: {best_params}')\n",
    "\n",
    "# Make predictions and evaluate performance\n",
    "y_pred = best_model.predict(X_test)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST \n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "grid4 = {\n",
    "    'n_estimators': [5,10,15],\n",
    "    'max_depth': [2,3],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "# Random Forest Regressor with GridSearchCV\n",
    "random_forest = RandomForestRegressor(random_state=21)\n",
    "random_forest_cv = GridSearchCV(random_forest, grid4, cv=5)\n",
    "random_forest_cv.fit(X_train, Y_train)\n",
    "random_forest_best = random_forest_cv.best_estimator_\n",
    "print(f'Best Parameters: {random_forest_best}')\n",
    "\n",
    "# Make predictions and evaluate performance\n",
    "y_pred = random_forest_best.predict(X_test)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for Random Forest\n",
    "grid4 = {\n",
    "    'n_estimators': [5,10,15],\n",
    "    'max_depth': [2,3],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "# Random Forest Regressor with GridSearchCV\n",
    "random_forest = RandomForestRegressor(random_state=21)\n",
    "random_forest_cv = GridSearchCV(random_forest, grid4, cv=10)\n",
    "random_forest_cv.fit(X_train, Y_train)\n",
    "random_forest_best = random_forest_cv.best_estimator_\n",
    "print(f'Best Parameters: {random_forest_best}')\n",
    "\n",
    "# Make predictions and evaluate performance\n",
    "y_pred = random_forest_best.predict(X_test)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADIENT BOOSTING\n",
    "\n",
    "# Define parameter grid for Gradient Boosting\n",
    "grid5 = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Gradient Boosting Regressor with GridSearchCV\n",
    "gradient_boosting = GradientBoostingRegressor(random_state=21)\n",
    "\n",
    "gradient_boosting_cv = GridSearchCV(gradient_boosting, grid5, cv=5)\n",
    "gradient_boosting_cv.fit(X_train, Y_train)\n",
    "gradient_boosting_best = gradient_boosting_cv.best_estimator_\n",
    "print(f'Best Parameters: {gradient_boosting_best}')\n",
    "\n",
    "# Make predictions and evaluate performance\n",
    "y_pred = gradient_boosting_best.predict(X_test)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for Gradient Boosting\n",
    "grid6 = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Gradient Boosting Regressor with GridSearchCV\n",
    "gradient_boosting = GradientBoostingRegressor(random_state=21)\n",
    "gradient_boosting_cv = GridSearchCV(gradient_boosting, grid6, cv=10)\n",
    "gradient_boosting_cv.fit(X_train, Y_train)\n",
    "gradient_boosting_best = gradient_boosting_cv.best_estimator_\n",
    "print(f'Best Parameters: {gradient_boosting_best}')\n",
    "\n",
    "# Make predictions and evaluate performance\n",
    "y_pred = best_model.predict(X_test)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE BAYES\n",
    "\n",
    "# Naive Bayes with GridSearchCV, tuning var_smoothing parameter\n",
    "grid = {'var_smoothing': np.logspace(0, -9, num=50)}\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes_cv = GridSearchCV(naive_bayes, grid, cv=5)\n",
    "naive_bayes_cv.fit(X_train, Y_train)\n",
    "naive_bayes_best = naive_bayes_cv.best_estimator_\n",
    "print(f'Best Parameters: {naive_bayes_best}')\n",
    "\n",
    "# Make predictions and evaluate performance\n",
    "y_pred = naive_bayes_best.predict(X_test)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Squared Error: {mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with GridSearchCV, tuning var_smoothing parameter\n",
    "grid = {'var_smoothing': np.logspace(0, -9, num=50)}\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes_cv = GridSearchCV(naive_bayes, grid, cv=10)\n",
    "naive_bayes_cv.fit(X_train, Y_train)\n",
    "naive_bayes_best = naive_bayes_cv.best_estimator_\n",
    "print(f'Best Parameters: {naive_bayes_best}')\n",
    "\n",
    "# Make predictions and evaluate performance\n",
    "y_pred = naive_bayes_best.predict(X_test)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLUSTERING \n",
    "\n",
    "# Initialize the StandardScaler\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "autoCrime_pb= crime[['pctUrban', 'medIncome', 'PctPopUnderPov', 'PctLess9thGrade', 'PctNotHSGrad',\n",
    "                     'PctBSorMore','PctEmploy', 'PctUnemployed',  'PctVacMore6Mos',\n",
    "                     'PctVacantBoarded','agePct12t29','agePct16t24','agePct65up','RentMedian',\n",
    "                     'racepctblack', 'racePctWhite', 'racePctAsian', 'racePctHisp', 'PctUsePubTrans','autoTheft','HousVacant']]\n",
    "autoCrime_pb =  autoCrime_pb.apply(pd.to_numeric, errors='coerce')\n",
    "autoCrime_pB = autoCrime_pb.replace('?', float('nan'))\n",
    "autoCrime_pb = autoCrime_pb.dropna()\n",
    "\n",
    "AutoCrime_standard = pd.DataFrame(StandardScaler().fit_transform(autoCrime_pb),columns = autoCrime_pb.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a range of possible k values\n",
    "k_values = range(2, 20)\n",
    "\n",
    "# Store results\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "\n",
    "# Evaluate K-Means for each k\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=21)\n",
    "    cluster_labels = kmeans.fit_predict(AutoCrime_standard)\n",
    "\n",
    "    # Append the inertia and silhouette score\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(AutoCrime_standard, cluster_labels))\n",
    "\n",
    "# Determine the optimal k using the Elbow Method\n",
    "optimal_k_elbow = np.diff(inertia).argmin() + 5  # +5 because np.diff reduces the array length by 1\n",
    "\n",
    "# Determine the optimal k using the Silhouette Score\n",
    "optimal_k_silhouette = np.argmax(silhouette_scores) + 5  # +5 because range starts from 5\n",
    "\n",
    "# Plot the Elbow Method\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(k_values, inertia, 'bx-')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.axvline(x=optimal_k_elbow, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# Plot the Silhouette Scores\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(k_values, silhouette_scores, 'bx-')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score for Optimal k')\n",
    "plt.axvline(x=optimal_k_silhouette, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# Display the optimal k values\n",
    "print(f\"Optimal number of clusters (Elbow Method): {optimal_k_elbow}\")\n",
    "print(f\"Optimal number of clusters (Silhouette Score): {optimal_k_silhouette}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(autoCrime_pb.loc[:,['pctUrban', 'medIncome','PctPopUnderPov', 'PctLess9thGrade', 'PctNotHSGrad', 'PctBSorMore','PctEmploy',\n",
    "                                 'PctUnemployed', 'HousVacant', 'PctVacantBoarded','PctVacMore6Mos','agePct12t29','agePct16t24','agePct65up','RentMedian',\n",
    "                                 'racepctblack', 'racePctWhite', 'racePctAsian', 'racePctHisp', 'PctUsePubTrans','autoTheft',]])    \\\n",
    "                        .reshape(-1, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "range_n_clusters = [2, 3, 4, 5, 6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=21)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\n",
    "        \"For n_clusters =\",\n",
    "        n_clusters,\n",
    "        \"The average silhouette_score is :\",\n",
    "        silhouette_avg,\n",
    "    )\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            ith_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(\n",
    "        X[:, 0], X[:, 1], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\")\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(\n",
    "        centers[:, 0],\n",
    "        centers[:, 1],\n",
    "        marker=\"o\",\n",
    "        c=\"white\",\n",
    "        alpha=1,\n",
    "        s=200,\n",
    "        edgecolor=\"k\",\n",
    "    )\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker=\"$%d$\" % i, alpha=1, s=50, edgecolor=\"k\")\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Silhouette analysis for KMeans clustering on data with n_clusters = %d\"\n",
    "        % n_clusters,\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
